{"cells":[{"cell_type":"markdown","metadata":{},"source":["# ASL Recognition - Jack Brummer\n","\n","Hello! My name is Jack Brummer and I am a recent graduate of Stevens Institute of Technology where I received my masters and bachelors in computer science"]},{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-07-08T17:09:03.737962Z","iopub.status.busy":"2023-07-08T17:09:03.737550Z","iopub.status.idle":"2023-07-08T17:09:03.750451Z","shell.execute_reply":"2023-07-08T17:09:03.749563Z","shell.execute_reply.started":"2023-07-08T17:09:03.737931Z"},"trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import matplotlib.pyplot as plt\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-07-08T17:09:03.760861Z","iopub.status.busy":"2023-07-08T17:09:03.760294Z","iopub.status.idle":"2023-07-08T17:09:03.885779Z","shell.execute_reply":"2023-07-08T17:09:03.884580Z","shell.execute_reply.started":"2023-07-08T17:09:03.760831Z"},"trusted":true},"outputs":[{"data":{"text/plain":["31"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["train_data = pd.read_csv('E:/competitions/asl-fingerspelling/asl-fingerspelling/train.csv')\n","train_data.head()\n","train_data.phrase.str.len().max()"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-07-08T17:09:03.888822Z","iopub.status.busy":"2023-07-08T17:09:03.888104Z","iopub.status.idle":"2023-07-08T17:09:06.901515Z","shell.execute_reply":"2023-07-08T17:09:06.900660Z","shell.execute_reply.started":"2023-07-08T17:09:03.888782Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>frame</th>\n","      <th>x_face_0</th>\n","      <th>x_face_1</th>\n","      <th>x_face_2</th>\n","      <th>x_face_3</th>\n","      <th>x_face_4</th>\n","      <th>x_face_5</th>\n","      <th>x_face_6</th>\n","      <th>x_face_7</th>\n","      <th>x_face_8</th>\n","      <th>...</th>\n","      <th>z_right_hand_11</th>\n","      <th>z_right_hand_12</th>\n","      <th>z_right_hand_13</th>\n","      <th>z_right_hand_14</th>\n","      <th>z_right_hand_15</th>\n","      <th>z_right_hand_16</th>\n","      <th>z_right_hand_17</th>\n","      <th>z_right_hand_18</th>\n","      <th>z_right_hand_19</th>\n","      <th>z_right_hand_20</th>\n","    </tr>\n","    <tr>\n","      <th>sequence_id</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1816796431</th>\n","      <td>0</td>\n","      <td>0.710588</td>\n","      <td>0.699951</td>\n","      <td>0.705657</td>\n","      <td>0.691768</td>\n","      <td>0.699669</td>\n","      <td>0.701980</td>\n","      <td>0.709724</td>\n","      <td>0.610405</td>\n","      <td>0.712660</td>\n","      <td>...</td>\n","      <td>-0.245855</td>\n","      <td>-0.269148</td>\n","      <td>-0.129743</td>\n","      <td>-0.251501</td>\n","      <td>-0.278687</td>\n","      <td>-0.266530</td>\n","      <td>-0.152852</td>\n","      <td>-0.257519</td>\n","      <td>-0.275822</td>\n","      <td>-0.266876</td>\n","    </tr>\n","    <tr>\n","      <th>1816796431</th>\n","      <td>1</td>\n","      <td>0.709525</td>\n","      <td>0.697582</td>\n","      <td>0.703713</td>\n","      <td>0.691016</td>\n","      <td>0.697576</td>\n","      <td>0.700467</td>\n","      <td>0.709796</td>\n","      <td>0.616540</td>\n","      <td>0.713729</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1816796431</th>\n","      <td>2</td>\n","      <td>0.711059</td>\n","      <td>0.700858</td>\n","      <td>0.706272</td>\n","      <td>0.693285</td>\n","      <td>0.700825</td>\n","      <td>0.703319</td>\n","      <td>0.711549</td>\n","      <td>0.615606</td>\n","      <td>0.715143</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1816796431</th>\n","      <td>3</td>\n","      <td>0.712799</td>\n","      <td>0.702518</td>\n","      <td>0.707840</td>\n","      <td>0.694899</td>\n","      <td>0.702445</td>\n","      <td>0.704794</td>\n","      <td>0.712483</td>\n","      <td>0.625044</td>\n","      <td>0.715677</td>\n","      <td>...</td>\n","      <td>-0.370770</td>\n","      <td>-0.408097</td>\n","      <td>-0.185217</td>\n","      <td>-0.325494</td>\n","      <td>-0.343373</td>\n","      <td>-0.328294</td>\n","      <td>-0.203126</td>\n","      <td>-0.315719</td>\n","      <td>-0.326104</td>\n","      <td>-0.314282</td>\n","    </tr>\n","    <tr>\n","      <th>1816796431</th>\n","      <td>4</td>\n","      <td>0.712349</td>\n","      <td>0.705451</td>\n","      <td>0.709918</td>\n","      <td>0.696006</td>\n","      <td>0.705180</td>\n","      <td>0.706928</td>\n","      <td>0.712685</td>\n","      <td>0.614356</td>\n","      <td>0.714875</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1848182207</th>\n","      <td>296</td>\n","      <td>0.657136</td>\n","      <td>0.635888</td>\n","      <td>0.643259</td>\n","      <td>0.619031</td>\n","      <td>0.633084</td>\n","      <td>0.631827</td>\n","      <td>0.630708</td>\n","      <td>0.533120</td>\n","      <td>0.626672</td>\n","      <td>...</td>\n","      <td>-0.143147</td>\n","      <td>-0.139659</td>\n","      <td>-0.066276</td>\n","      <td>-0.130910</td>\n","      <td>-0.127341</td>\n","      <td>-0.106674</td>\n","      <td>-0.083439</td>\n","      <td>-0.124994</td>\n","      <td>-0.119394</td>\n","      <td>-0.101404</td>\n","    </tr>\n","    <tr>\n","      <th>1848182207</th>\n","      <td>297</td>\n","      <td>0.655706</td>\n","      <td>0.635570</td>\n","      <td>0.642730</td>\n","      <td>0.618637</td>\n","      <td>0.632830</td>\n","      <td>0.631554</td>\n","      <td>0.630344</td>\n","      <td>0.531868</td>\n","      <td>0.626445</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1848182207</th>\n","      <td>298</td>\n","      <td>0.653681</td>\n","      <td>0.636057</td>\n","      <td>0.643054</td>\n","      <td>0.618643</td>\n","      <td>0.633258</td>\n","      <td>0.631800</td>\n","      <td>0.630059</td>\n","      <td>0.531178</td>\n","      <td>0.625990</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1848182207</th>\n","      <td>299</td>\n","      <td>0.654293</td>\n","      <td>0.635543</td>\n","      <td>0.642558</td>\n","      <td>0.617969</td>\n","      <td>0.632699</td>\n","      <td>0.631167</td>\n","      <td>0.629263</td>\n","      <td>0.531019</td>\n","      <td>0.625069</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1848182207</th>\n","      <td>300</td>\n","      <td>0.655109</td>\n","      <td>0.634491</td>\n","      <td>0.641743</td>\n","      <td>0.617779</td>\n","      <td>0.631771</td>\n","      <td>0.630562</td>\n","      <td>0.629580</td>\n","      <td>0.533534</td>\n","      <td>0.626065</td>\n","      <td>...</td>\n","      <td>-0.196495</td>\n","      <td>-0.202258</td>\n","      <td>-0.101019</td>\n","      <td>-0.179127</td>\n","      <td>-0.182757</td>\n","      <td>-0.169923</td>\n","      <td>-0.116275</td>\n","      <td>-0.173652</td>\n","      <td>-0.176919</td>\n","      <td>-0.167582</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>162699 rows × 1630 columns</p>\n","</div>"],"text/plain":["             frame  x_face_0  x_face_1  x_face_2  x_face_3  x_face_4  \\\n","sequence_id                                                            \n","1816796431       0  0.710588  0.699951  0.705657  0.691768  0.699669   \n","1816796431       1  0.709525  0.697582  0.703713  0.691016  0.697576   \n","1816796431       2  0.711059  0.700858  0.706272  0.693285  0.700825   \n","1816796431       3  0.712799  0.702518  0.707840  0.694899  0.702445   \n","1816796431       4  0.712349  0.705451  0.709918  0.696006  0.705180   \n","...            ...       ...       ...       ...       ...       ...   \n","1848182207     296  0.657136  0.635888  0.643259  0.619031  0.633084   \n","1848182207     297  0.655706  0.635570  0.642730  0.618637  0.632830   \n","1848182207     298  0.653681  0.636057  0.643054  0.618643  0.633258   \n","1848182207     299  0.654293  0.635543  0.642558  0.617969  0.632699   \n","1848182207     300  0.655109  0.634491  0.641743  0.617779  0.631771   \n","\n","             x_face_5  x_face_6  x_face_7  x_face_8  ...  z_right_hand_11  \\\n","sequence_id                                          ...                    \n","1816796431   0.701980  0.709724  0.610405  0.712660  ...        -0.245855   \n","1816796431   0.700467  0.709796  0.616540  0.713729  ...              NaN   \n","1816796431   0.703319  0.711549  0.615606  0.715143  ...              NaN   \n","1816796431   0.704794  0.712483  0.625044  0.715677  ...        -0.370770   \n","1816796431   0.706928  0.712685  0.614356  0.714875  ...              NaN   \n","...               ...       ...       ...       ...  ...              ...   \n","1848182207   0.631827  0.630708  0.533120  0.626672  ...        -0.143147   \n","1848182207   0.631554  0.630344  0.531868  0.626445  ...              NaN   \n","1848182207   0.631800  0.630059  0.531178  0.625990  ...              NaN   \n","1848182207   0.631167  0.629263  0.531019  0.625069  ...              NaN   \n","1848182207   0.630562  0.629580  0.533534  0.626065  ...        -0.196495   \n","\n","             z_right_hand_12  z_right_hand_13  z_right_hand_14  \\\n","sequence_id                                                      \n","1816796431         -0.269148        -0.129743        -0.251501   \n","1816796431               NaN              NaN              NaN   \n","1816796431               NaN              NaN              NaN   \n","1816796431         -0.408097        -0.185217        -0.325494   \n","1816796431               NaN              NaN              NaN   \n","...                      ...              ...              ...   \n","1848182207         -0.139659        -0.066276        -0.130910   \n","1848182207               NaN              NaN              NaN   \n","1848182207               NaN              NaN              NaN   \n","1848182207               NaN              NaN              NaN   \n","1848182207         -0.202258        -0.101019        -0.179127   \n","\n","             z_right_hand_15  z_right_hand_16  z_right_hand_17  \\\n","sequence_id                                                      \n","1816796431         -0.278687        -0.266530        -0.152852   \n","1816796431               NaN              NaN              NaN   \n","1816796431               NaN              NaN              NaN   \n","1816796431         -0.343373        -0.328294        -0.203126   \n","1816796431               NaN              NaN              NaN   \n","...                      ...              ...              ...   \n","1848182207         -0.127341        -0.106674        -0.083439   \n","1848182207               NaN              NaN              NaN   \n","1848182207               NaN              NaN              NaN   \n","1848182207               NaN              NaN              NaN   \n","1848182207         -0.182757        -0.169923        -0.116275   \n","\n","             z_right_hand_18  z_right_hand_19  z_right_hand_20  \n","sequence_id                                                     \n","1816796431         -0.257519        -0.275822        -0.266876  \n","1816796431               NaN              NaN              NaN  \n","1816796431               NaN              NaN              NaN  \n","1816796431         -0.315719        -0.326104        -0.314282  \n","1816796431               NaN              NaN              NaN  \n","...                      ...              ...              ...  \n","1848182207         -0.124994        -0.119394        -0.101404  \n","1848182207               NaN              NaN              NaN  \n","1848182207               NaN              NaN              NaN  \n","1848182207               NaN              NaN              NaN  \n","1848182207         -0.173652        -0.176919        -0.167582  \n","\n","[162699 rows x 1630 columns]"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["file_id = 5414471\n","path = f'E:/competitions/asl-fingerspelling/asl-fingerspelling/train_landmarks/{file_id}.parquet'\n","sign = pd.read_parquet(path)\n","sign"]},{"cell_type":"markdown","metadata":{},"source":["## Model "]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-07-08T17:56:22.557488Z","iopub.status.busy":"2023-07-08T17:56:22.557092Z","iopub.status.idle":"2023-07-08T17:56:22.564432Z","shell.execute_reply":"2023-07-08T17:56:22.563429Z","shell.execute_reply.started":"2023-07-08T17:56:22.557455Z"},"trusted":true},"outputs":[],"source":["from keras.layers import Input, LSTM, Bidirectional, Concatenate\n","from keras.models import Sequential, Model\n","\n","using_drive = True\n","\n","class ASL_Transformer_Model:\n","    \n","    def __init__(self):\n","        self.train_path = '/kaggle/input/asl-fingerspelling/train.csv' if not using_drive else \"E:/competitions/asl-fingerspelling/asl-fingerspelling/train.csv\"\n","        self.train = pd.read_csv(self.train_path)\n","        self.sequence_ids = self.train['sequence_ids']\n","        self.num_sequences = len(self.sequence_ids)\n","        self.max_sequence_length = self.train.phrase.str.len().max()\n","        self.num_seqs = len(self.train.phrase)\n","        self.num_decoder_tokens = 10\n","        self.num_encoder_tokens = 10\n","\n","        # input texts -> map from sequence_id to train landmark\n","        self.input_texts = self.train['sequence_id']\n","        # target texts -> the respective phrase for each sequence id\n","        self.target_texts = self.train['phrase']\n","\n","        \n","    def get_sign_from_path(self, path, sequence_id):\n","        \n","        f'/kaggle/input/asl-fingerspelling/train_landmarks/{file_id}.parquet'\n","        sign = pd.read_parquet(path)\n","        return sign\n","    \n","    def get_frames(self, train_landmark, sequence_id):\n","        frames = self.train.loc[self.train['sequence_id'] == sequence_id]\n","        return frames\n","\n","    def get_phrase(self, sequence_id):\n","        phrase = self.train.loc[self.train['sequence_id'] == sequence_id]['phrase']\n","        return phrase\n","\n","    def encoder(self):\n","        latent_dim = 256\n","\n","        # inputs of the encoder network\n","        encoder_inputs = Input(shape=(None, self.num_encoder_tokens), \n","                            name='encoder_inputs')\n","\n","        # set the LSTM layer\n","        encoder_bilstm = Bidirectional(LSTM(latent_dim, return_state=True, \n","                            dropout=0.5, name='encoder_lstm'))\n","\n","        _, forward_h, forward_c, back_h, back_c = encoder_bilstm(encoder_inputs)\n","\n","        # build the encoder network model\n","\n","        state_h = Concatenate()([forward_h, back_h])\n","        state_c = Concatenate()([forward_c, back_c])\n","\n","        encoder_model = Model(inputs=encoder_inputs, \n","                            outputs=[state_h, state_c],\n","                            name='encoder')\n","        return encoder_model\n","    \n","    def decoder(self):\n","        decoder_input_h = Input(shape=(512,), name='decoder_input_h')\n","        decoder_input_c = Input(shape=(512,), name='decoder_input_c')\n","        decoder_input_x = Input(shape=(None, self.num_decoder_tokens), name='decoder_input_x')\n","\n","        # set the LSTM layer\n","        decoder_lstm = LSTM(512, return_sequences=True, \n","                            return_state=True, dropout=0.5, name='decoder_lstm')\n","        decoder_lstm_outputs, state_h, state_c = decoder_lstm(decoder_input_x, \n","                                                            initial_state=[decoder_input_h, decoder_input_c]) # type: ignore\n","\n","        # set the dense layer\n","        decoder_dense = Dense(self.num_decoder_tokens, activation='softmax', name='decoder_dense')\n","        decoder_outputs = decoder_dense(decoder_lstm_outputs)\n","\n","        # build the decoder network model\n","        decoder_model = Model(inputs=[decoder_input_x, decoder_input_h, decoder_input_c],\n","                            outputs=[decoder_outputs, state_h, state_c],\n","                            name='decoder')\n","        \n","        return decoder_model\n","    \n","    "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from tensorflow.keras.layers import TextVectorization\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","def makeSequence(max_len, lines):\n","    tokenizer = Tokenizer(char_level=True, filters='')\n","    tokenizer.fit_on_texts(lines)\n","    seqs = tokenizer.texts_to_sequences(lines)\n","    seqs_pad = pad_sequences(seqs, maxlen=max_len, padding='post')\n","    return seqs_pad, tokenizer.word_index\n","\n","\n","encoder_input_seq, input_token_index = makeSequence(max_encoder_seq_length, \n","                                                      input_texts)\n","decoder_input_seq, target_token_index = makeSequence(max_decoder_seq_length, \n","                                                       target_texts)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":4}
